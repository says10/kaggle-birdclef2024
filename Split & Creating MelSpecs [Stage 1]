{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"}],"dockerImageVersionId":30407,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Let's Think of a Better Split Method","metadata":{"papermill":{"duration":0.018531,"end_time":"2021-04-27T16:16:17.44056","exception":false,"start_time":"2021-04-27T16:16:17.422029","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nimport librosa as lb\nimport librosa.display as lbd\nimport soundfile as sf\nfrom  soundfile import SoundFile\nimport pandas as pd\nfrom  IPython.display import Audio\nfrom pathlib import Path\n\nfrom matplotlib import pyplot as plt\n\nfrom tqdm.notebook import tqdm\nimport joblib, json, re\n\nfrom  sklearn.model_selection  import StratifiedKFold\ntqdm.pandas()","metadata":{"id":"2dt7oG43VAqc","papermill":{"duration":2.637633,"end_time":"2021-04-27T16:16:20.164867","exception":false,"start_time":"2021-04-27T16:16:17.527234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T07:58:16.911435Z","iopub.execute_input":"2024-06-02T07:58:16.912484Z","iopub.status.idle":"2024-06-02T07:58:17.596671Z","shell.execute_reply.started":"2024-06-02T07:58:16.912440Z","shell.execute_reply":"2024-06-02T07:58:17.595613Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/birdclef-2024/train_metadata.csv')\ndf['secondary_labels'] = df['secondary_labels'].apply(lambda x: re.findall(r\"'(\\w+)'\", x))\ndf['len_sec_labels'] = df['secondary_labels'].map(len)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.599339Z","iopub.execute_input":"2024-06-02T07:58:17.600242Z","iopub.status.idle":"2024-06-02T07:58:17.804809Z","shell.execute_reply.started":"2024-06-02T07:58:17.600196Z","shell.execute_reply":"2024-06-02T07:58:17.803642Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df[df.len_sec_labels>0].sample(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.806274Z","iopub.execute_input":"2024-06-02T07:58:17.806701Z","iopub.status.idle":"2024-06-02T07:58:17.837257Z","shell.execute_reply.started":"2024-06-02T07:58:17.806656Z","shell.execute_reply":"2024-06-02T07:58:17.836260Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      primary_label   secondary_labels                    type  latitude  \\\n2753        blakit1          [zitcis1]                ['call']   41.9570   \n21136       ruftre2  [brcful1, rewbul]                ['call']   18.8897   \n237         ashpri1           [revbul]  ['alarm call', 'call']   21.0484   \n\n       longitude        scientific_name     common_name  \\\n2753     -8.7464         Milvus migrans      Black Kite   \n21136    73.1232  Dendrocitta vagabunda  Rufous Treepie   \n237      75.8510        Prinia socialis     Ashy Prinia   \n\n                         author  \\\n2753               Jorge Leitão   \n21136            Saurabh Sawant   \n237    Lakshmikant Rajaram Neve   \n\n                                                 license  rating  \\\n2753   Creative Commons Attribution-NonCommercial-Sha...     2.5   \n21136  Creative Commons Attribution-NonCommercial-Sha...     4.5   \n237    Creative Commons Attribution-NonCommercial-Sha...     2.5   \n\n                                     url              filename  len_sec_labels  \n2753   https://www.xeno-canto.org/422663  blakit1/XC422663.ogg               1  \n21136  https://www.xeno-canto.org/120592  ruftre2/XC120592.ogg               2  \n237    https://www.xeno-canto.org/384390  ashpri1/XC384390.ogg               1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primary_label</th>\n      <th>secondary_labels</th>\n      <th>type</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>scientific_name</th>\n      <th>common_name</th>\n      <th>author</th>\n      <th>license</th>\n      <th>rating</th>\n      <th>url</th>\n      <th>filename</th>\n      <th>len_sec_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2753</th>\n      <td>blakit1</td>\n      <td>[zitcis1]</td>\n      <td>['call']</td>\n      <td>41.9570</td>\n      <td>-8.7464</td>\n      <td>Milvus migrans</td>\n      <td>Black Kite</td>\n      <td>Jorge Leitão</td>\n      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n      <td>2.5</td>\n      <td>https://www.xeno-canto.org/422663</td>\n      <td>blakit1/XC422663.ogg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21136</th>\n      <td>ruftre2</td>\n      <td>[brcful1, rewbul]</td>\n      <td>['call']</td>\n      <td>18.8897</td>\n      <td>73.1232</td>\n      <td>Dendrocitta vagabunda</td>\n      <td>Rufous Treepie</td>\n      <td>Saurabh Sawant</td>\n      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n      <td>4.5</td>\n      <td>https://www.xeno-canto.org/120592</td>\n      <td>ruftre2/XC120592.ogg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>ashpri1</td>\n      <td>[revbul]</td>\n      <td>['alarm call', 'call']</td>\n      <td>21.0484</td>\n      <td>75.8510</td>\n      <td>Prinia socialis</td>\n      <td>Ashy Prinia</td>\n      <td>Lakshmikant Rajaram Neve</td>\n      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n      <td>2.5</td>\n      <td>https://www.xeno-canto.org/384390</td>\n      <td>ashpri1/XC384390.ogg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.primary_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.838600Z","iopub.execute_input":"2024-06-02T07:58:17.838999Z","iopub.status.idle":"2024-06-02T07:58:17.853339Z","shell.execute_reply.started":"2024-06-02T07:58:17.838956Z","shell.execute_reply":"2024-06-02T07:58:17.852032Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"zitcis1    500\nlirplo     500\nlitgre1    500\ncomgre     500\ncomkin1    500\n          ... \nblaeag1      6\nwynlau1      6\nniwpig1      5\nasiope1      5\nintegr       5\nName: primary_label, Length: 182, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Something has to be done for Birds with <= 1 samples.","metadata":{}},{"cell_type":"markdown","source":"## Also the fact that we have to perform inference in 2 hours w/ CPU, I think best solution is just to have single split rather than using multiple folds.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\n\ndef birds_stratified_split(df, target_col, test_size=0.2):\n    class_counts = df[target_col].value_counts()\n    low_count_classes = class_counts[class_counts < 2].index.tolist() ### Birds with single counts\n\n    df['train'] = df[target_col].isin(low_count_classes)\n\n    train_df, val_df = train_test_split(df[~df['train']], test_size=test_size, stratify=df[~df['train']][target_col], random_state=42)\n\n    train_df = pd.concat([train_df, df[df['train']]], axis=0).reset_index(drop=True)\n\n    # Remove the 'valid' column\n    train_df.drop('train', axis=1, inplace=True)\n    val_df.drop('train', axis=1, inplace=True)\n\n    return train_df, val_df","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.857270Z","iopub.execute_input":"2024-06-02T07:58:17.858003Z","iopub.status.idle":"2024-06-02T07:58:17.866812Z","shell.execute_reply.started":"2024-06-02T07:58:17.857945Z","shell.execute_reply":"2024-06-02T07:58:17.865694Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = birds_stratified_split(df, 'primary_label', 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.868201Z","iopub.execute_input":"2024-06-02T07:58:17.868600Z","iopub.status.idle":"2024-06-02T07:58:17.955492Z","shell.execute_reply.started":"2024-06-02T07:58:17.868561Z","shell.execute_reply":"2024-06-02T07:58:17.954312Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.primary_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.956746Z","iopub.execute_input":"2024-06-02T07:58:17.957035Z","iopub.status.idle":"2024-06-02T07:58:17.969108Z","shell.execute_reply.started":"2024-06-02T07:58:17.957007Z","shell.execute_reply":"2024-06-02T07:58:17.967893Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"zitcis1    500\nlirplo     500\nlitgre1    500\ncomgre     500\ncomkin1    500\n          ... \nblaeag1      6\nwynlau1      6\nniwpig1      5\nasiope1      5\nintegr       5\nName: primary_label, Length: 182, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_df.primary_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.970584Z","iopub.execute_input":"2024-06-02T07:58:17.970926Z","iopub.status.idle":"2024-06-02T07:58:17.982514Z","shell.execute_reply.started":"2024-06-02T07:58:17.970896Z","shell.execute_reply":"2024-06-02T07:58:17.981364Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"graher1    400\nlitgre1    400\nwoosan     400\neurcoo     400\ngrnsan     400\n          ... \nwynlau1      5\nblaeag1      5\nasiope1      4\nniwpig1      4\nintegr       4\nName: primary_label, Length: 182, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"valid_df.primary_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:17.984237Z","iopub.execute_input":"2024-06-02T07:58:17.984736Z","iopub.status.idle":"2024-06-02T07:58:17.995002Z","shell.execute_reply.started":"2024-06-02T07:58:17.984695Z","shell.execute_reply":"2024-06-02T07:58:17.993923Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"houspa     100\nbarswa     100\nblrwar1    100\ncomros     100\ngraher1    100\n          ... \ndarter2      1\nniwpig1      1\nbncwoo3      1\nblaeag1      1\npaisto1      1\nName: primary_label, Length: 182, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"class Config:\n    sampling_rate = 32000\n    duration = 5 \n    fmin = 0\n    fmax = None\n    audios_path = Path(\"/kaggle/input/birdclef-2024/train_audio\")\n    out_dir_train = Path(\"specs/train\") \n    \n    out_dir_valid = Path(\"specs/valid\") \n","metadata":{"papermill":{"duration":0.027531,"end_time":"2021-04-27T16:16:20.271347","exception":false,"start_time":"2021-04-27T16:16:20.243816","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T07:58:17.996304Z","iopub.execute_input":"2024-06-02T07:58:17.996669Z","iopub.status.idle":"2024-06-02T07:58:18.002853Z","shell.execute_reply.started":"2024-06-02T07:58:17.996630Z","shell.execute_reply":"2024-06-02T07:58:18.001881Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"Config.out_dir_train.mkdir(exist_ok=True, parents=True)\nConfig.out_dir_valid.mkdir(exist_ok=True, parents=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:18.004134Z","iopub.execute_input":"2024-06-02T07:58:18.004463Z","iopub.status.idle":"2024-06-02T07:58:18.011267Z","shell.execute_reply.started":"2024-06-02T07:58:18.004433Z","shell.execute_reply":"2024-06-02T07:58:18.010340Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def get_audio_info(filepath):\n    \"\"\"Get some properties from  an audio file\"\"\"\n    with SoundFile(filepath) as f:\n        sr = f.samplerate\n        frames = f.frames\n        duration = float(frames)/sr\n    return {\"frames\": frames, \"sr\": sr, \"duration\": duration}","metadata":{"papermill":{"duration":0.026875,"end_time":"2021-04-27T16:16:20.351194","exception":false,"start_time":"2021-04-27T16:16:20.324319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T07:58:18.012615Z","iopub.execute_input":"2024-06-02T07:58:18.013085Z","iopub.status.idle":"2024-06-02T07:58:18.019465Z","shell.execute_reply.started":"2024-06-02T07:58:18.013045Z","shell.execute_reply":"2024-06-02T07:58:18.018484Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def add_path_df(df):\n    \n    df[\"path\"] = [str(Config.audios_path/filename) for filename in df.filename]\n    df = df.reset_index(drop=True)\n    pool = joblib.Parallel(2)\n    mapper = joblib.delayed(get_audio_info)\n    tasks = [mapper(filepath) for filepath in df.path]\n    df2 =  pd.DataFrame(pool(tqdm(tasks))).reset_index(drop=True)\n    df = pd.concat([df,df2], axis=1).reset_index(drop=True)\n\n    return df","metadata":{"id":"Kmh6xx5_NCjJ","outputId":"ad61f09f-6f0e-4204-c658-21112e051785","papermill":{"duration":0.031496,"end_time":"2021-04-27T16:16:20.401055","exception":false,"start_time":"2021-04-27T16:16:20.369559","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T07:58:18.020888Z","iopub.execute_input":"2024-06-02T07:58:18.021225Z","iopub.status.idle":"2024-06-02T07:58:18.032388Z","shell.execute_reply.started":"2024-06-02T07:58:18.021196Z","shell.execute_reply":"2024-06-02T07:58:18.031442Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T07:58:18.037788Z","iopub.execute_input":"2024-06-02T07:58:18.038203Z","iopub.status.idle":"2024-06-02T07:58:18.043530Z","shell.execute_reply.started":"2024-06-02T07:58:18.038160Z","shell.execute_reply":"2024-06-02T07:58:18.042434Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_df = add_path_df(train_df)","metadata":{"papermill":{"duration":0.017674,"end_time":"2021-04-27T16:16:20.436943","exception":false,"start_time":"2021-04-27T16:16:20.419269","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T07:58:18.044767Z","iopub.execute_input":"2024-06-02T07:58:18.045095Z","iopub.status.idle":"2024-06-02T08:00:16.286822Z","shell.execute_reply.started":"2024-06-02T07:58:18.045053Z","shell.execute_reply":"2024-06-02T08:00:16.285687Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19567 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3824200896f44c02942defe37c34d6c5"}},"metadata":{}}]},{"cell_type":"code","source":"valid_df = add_path_df(valid_df)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:00:16.288267Z","iopub.execute_input":"2024-06-02T08:00:16.288592Z","iopub.status.idle":"2024-06-02T08:00:46.947197Z","shell.execute_reply.started":"2024-06-02T08:00:16.288558Z","shell.execute_reply":"2024-06-02T08:00:46.946318Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4892 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"841aecea67684ac185861ffaed6706c9"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"duration\"].describe()","metadata":{"papermill":{"duration":0.257618,"end_time":"2021-04-27T16:18:04.144335","exception":false,"start_time":"2021-04-27T16:18:03.886717","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T08:00:46.948750Z","iopub.execute_input":"2024-06-02T08:00:46.949250Z","iopub.status.idle":"2024-06-02T08:00:46.962922Z","shell.execute_reply.started":"2024-06-02T08:00:46.949201Z","shell.execute_reply":"2024-06-02T08:00:46.961760Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"count    19567.000000\nmean        41.858233\nstd         98.451733\nmin          0.470000\n25%         11.180406\n50%         22.230219\n75%         44.564906\nmax       4670.641625\nName: duration, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"def compute_melspec(y, sr, n_mels, fmin, fmax):\n    \"\"\"\n    Computes a mel-spectrogram and puts it at decibel scale\n    Arguments:\n        y {np array} -- signal\n        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n    Returns:\n        np array -- Mel-spectrogram\n    \"\"\"\n    melspec = lb.feature.melspectrogram(\n        y=y, sr=sr, n_mels=n_mels, fmin=fmin, fmax=fmax,\n    )\n\n    melspec = lb.power_to_db(melspec).astype(np.float32)\n    return melspec","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:00:46.964266Z","iopub.execute_input":"2024-06-02T08:00:46.964889Z","iopub.status.idle":"2024-06-02T08:00:46.971198Z","shell.execute_reply.started":"2024-06-02T08:00:46.964856Z","shell.execute_reply":"2024-06-02T08:00:46.970143Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def mono_to_color(X, eps=1e-6, mean=None, std=None):\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n    \n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V\n\ndef crop_or_pad(y, length, is_train=True, start=None):\n    if len(y) < length:\n        y = np.concatenate([y, np.zeros(length - len(y))])\n        \n        n_repeats = length // len(y)\n        epsilon = length % len(y)\n        \n        y = np.concatenate([y]*n_repeats + [y[:epsilon]])\n        \n    elif len(y) > length:\n        if not is_train:\n            start = start or 0\n        else:\n            start = start or np.random.randint(len(y) - length)\n\n        y = y[start:start + length]\n\n    return y","metadata":{"id":"-Nlw4E5UVAqi","papermill":{"duration":0.036932,"end_time":"2021-04-27T16:18:04.507902","exception":false,"start_time":"2021-04-27T16:18:04.47097","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T08:00:46.972672Z","iopub.execute_input":"2024-06-02T08:00:46.973649Z","iopub.status.idle":"2024-06-02T08:00:46.986170Z","shell.execute_reply.started":"2024-06-02T08:00:46.973609Z","shell.execute_reply":"2024-06-02T08:00:46.985139Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AudioToImage:\n    def __init__(self, sr=Config.sampling_rate, n_mels=128, fmin=Config.fmin, fmax=Config.fmax, duration=Config.duration, step=None, res_type=\"kaiser_fast\", resample=True, train = True):\n\n        self.sr = sr\n        self.n_mels = n_mels\n        self.fmin = fmin\n        self.fmax = fmax or self.sr//2\n\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        self.step = step or self.audio_length\n        \n        self.res_type = res_type\n        self.resample = resample\n\n        self.train = train\n    def audio_to_image(self, audio):\n        melspec = compute_melspec(audio, self.sr, self.n_mels, self.fmin, self.fmax ) \n        image = mono_to_color(melspec)\n#         compute_melspec(y, sr, n_mels, fmin, fmax)\n        return image\n\n    def __call__(self, row, save=True):\n\n      audio, orig_sr = sf.read(row.path, dtype=\"float32\")\n\n      if self.resample and orig_sr != self.sr:\n        audio = lb.resample(audio, orig_sr, self.sr, res_type=self.res_type)\n        \n      audios = [audio[i:i+self.audio_length] for i in range(0, max(1, len(audio) - self.audio_length + 1), self.step)]\n      audios[-1] = crop_or_pad(audios[-1] , length=self.audio_length)\n      images = [self.audio_to_image(audio) for audio in audios]\n      images = np.stack(images)\n        \n      if save:\n        if self.train:\n            path = Config.out_dir_train/f\"{row.filename}.npy\"\n        else:\n            path = Config.out_dir_valid/f\"{row.filename}.npy\"\n            \n        path.parent.mkdir(exist_ok=True, parents=True)\n        np.save(str(path), images)\n      else:\n        return  row.filename, images","metadata":{"papermill":{"duration":0.039542,"end_time":"2021-04-27T16:18:04.570629","exception":false,"start_time":"2021-04-27T16:18:04.531087","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T08:00:46.987321Z","iopub.execute_input":"2024-06-02T08:00:46.987667Z","iopub.status.idle":"2024-06-02T08:00:47.003907Z","shell.execute_reply.started":"2024-06-02T08:00:46.987628Z","shell.execute_reply":"2024-06-02T08:00:47.002745Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:00:47.005249Z","iopub.execute_input":"2024-06-02T08:00:47.005613Z","iopub.status.idle":"2024-06-02T08:00:47.015029Z","shell.execute_reply.started":"2024-06-02T08:00:47.005584Z","shell.execute_reply":"2024-06-02T08:00:47.013995Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_audios_as_images(df, train = True):\n    pool = joblib.Parallel(2)\n    \n    converter = AudioToImage(step=int(Config.duration*0.666*Config.sampling_rate),train=train)\n    mapper = joblib.delayed(converter)\n    tasks = [mapper(row) for row in df.itertuples(False)]\n    pool(tqdm(tasks))","metadata":{"papermill":{"duration":0.032362,"end_time":"2021-04-27T16:18:04.626619","exception":false,"start_time":"2021-04-27T16:18:04.594257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T08:00:47.016344Z","iopub.execute_input":"2024-06-02T08:00:47.016741Z","iopub.status.idle":"2024-06-02T08:00:47.023927Z","shell.execute_reply.started":"2024-06-02T08:00:47.016699Z","shell.execute_reply":"2024-06-02T08:00:47.022953Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"get_audios_as_images(train_df, train = True)\n","metadata":{"papermill":{"duration":4117.309995,"end_time":"2021-04-27T17:26:41.959921","exception":false,"start_time":"2021-04-27T16:18:04.649926","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T08:00:47.025170Z","iopub.execute_input":"2024-06-02T08:00:47.025545Z","iopub.status.idle":"2024-06-02T08:57:35.865341Z","shell.execute_reply.started":"2024-06-02T08:00:47.025511Z","shell.execute_reply":"2024-06-02T08:57:35.864326Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/19567 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a786ed82dd4318a14698b11fec85b2"}},"metadata":{}}]},{"cell_type":"code","source":"get_audios_as_images(valid_df, train = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:57:35.866818Z","iopub.execute_input":"2024-06-02T08:57:35.867134Z","iopub.status.idle":"2024-06-02T09:11:59.884232Z","shell.execute_reply.started":"2024-06-02T08:57:35.867104Z","shell.execute_reply":"2024-06-02T09:11:59.882593Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4892 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2918f3a7e1ea45d3ab62426ee456ab5d"}},"metadata":{}}]},{"cell_type":"code","source":"import zipfile\nimport os\n\n# Function to zip a folder with high compression\ndef zip_folder_high_compression(folder_path, zip_path):\n    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n        for root, dirs, files in os.walk(folder_path):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, start=folder_path)\n                zipf.write(file_path, arcname)\n\n\n# Paths\nfolder_path = '/kaggle/working/specs'\nzip_path = '/kaggle/working/my_folder_high_compression.zip'\n\n# Compress the folder with high compression\nzip_folder_high_compression(folder_path, zip_path)\n\nprint(\"Folder compressed successfully with high compression.\")\n\n# Verify the ZIP file is created\nprint(os.listdir('/kaggle/working/'))\n\n","metadata":{"papermill":{"duration":0.027772,"end_time":"2021-04-27T17:26:42.374518","exception":false,"start_time":"2021-04-27T17:26:42.346746","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-02T09:11:59.886452Z","iopub.execute_input":"2024-06-02T09:11:59.887241Z","iopub.status.idle":"2024-06-02T09:22:42.565982Z","shell.execute_reply.started":"2024-06-02T09:11:59.887187Z","shell.execute_reply":"2024-06-02T09:22:42.564902Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Folder compressed successfully with high compression.\n['my_folder_high_compression.zip', 'specs', '.virtual_documents']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}